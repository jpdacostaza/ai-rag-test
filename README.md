# Advanced LLM Backend with Tool-Augmented Intelligence & Enhanced Human Logging

> **ğŸ“š Documentation**: For comprehensive project documentation, reports, and technical details, see the [readme/](readme/) directory which contains all project documentation organized by category.

## ğŸš€ Project Overview

This is a **production-ready, enterprise-grade** FastAPI backend that provides **human-like reasoning** and **tool-augmented AI** capabilities with comprehensive system monitoring and **beautiful human-readable logging**. The system combines real-time tools, semantic memory, robust caching, fault-tolerant architecture, and OpenAI-compatible APIs to create an intelligent assistant that can:

- ğŸ¤– **Local LLM with Ollama** - Default llama3.2:3b model with automatic verification and download
- ğŸ¨ **Enhanced Human-Readable Logging** - Beautiful, colorful logs with emojis and clear status indicators
- ğŸ§  **Advanced Embeddings** - Qwen/Qwen3-Embedding-0.6B model with automatic fallback support
- ğŸ”´ **Robust Redis Integration** - Connection pooling, health monitoring, and graceful degradation
- ğŸ **Secure Python Execution** - Sandboxed code execution with timeout protection
- ğŸŒ **Intelligent Web Search** - Real-time web search with automatic knowledge storage
- ğŸ“š **Wikipedia Integration** - Search and retrieve summaries with caching
- ğŸ§® **Mathematical Calculator** - Safe expression evaluation with comprehensive operators
- ğŸŒ¡ï¸ **Weather & Time Services** - Real-time weather and timezone information
- ğŸ’¾ **Semantic Memory** - Vector embeddings with ChromaDB for knowledge storage
- ğŸš€ **Streaming Responses** - Real-time API responses with error recovery
- ğŸ‘€ **System Watchdog** - Automated health monitoring and recovery
- ğŸ¥ **Health Checks** - Comprehensive service monitoring and diagnostics
- ğŸ”— **OpenWebUI Compatible** - Seamless integration with modern frontends
- ğŸ“¥ **File Upload & RAG** - Document processing with vector storage and semantic search

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenWebUI     â”‚â—„â”€â”€â–ºâ”‚  FastAPI Backend â”‚â—„â”€â”€â–ºâ”‚     Ollama      â”‚
â”‚   (Frontend)    â”‚    â”‚  (Tool Engine)   â”‚    â”‚  (llama3.2:3b)  â”‚
â”‚    Port 3000    â”‚    â”‚    Port 8001     â”‚    â”‚   Port 11434    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼           â–¼           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Redis    â”‚ â”‚  ChromaDB   â”‚ â”‚ AI Tools    â”‚
            â”‚ (Cache &    â”‚ â”‚ (Semantic   â”‚ â”‚ (Real-time  â”‚
            â”‚ Sessions)   â”‚ â”‚  Memory)    â”‚ â”‚ Functions)  â”‚
            â”‚ Port 6379   â”‚ â”‚ Port 8002   â”‚ â”‚ (Weather,   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ Time, etc.) â”‚
                    â–²           â–²           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â–¼           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Enhanced Logging     â”‚
                    â”‚   & System Watchdog     â”‚
                    â”‚  (Health Monitoring &   â”‚
                    â”‚   Automatic Recovery)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Request Flow
All user requests flow through your backend - **no direct access to Ollama**:

```
User â†’ OpenWebUI â†’ Your Backend â†’ [Tools/RAG/Cache] â†’ Ollama â†’ Response
```

**Security & Control:**
- âœ… All requests authenticated with API key
- âœ… No direct Ollama access (port 11434 internal only)
- âœ… Complete request logging and monitoring
- âœ… Rate limiting and caching handled by backend
- âœ… RAG and tool integration on every request

## ğŸ“ Complete Project Structure

```
opt/backend/
â”œâ”€â”€ ğŸ¯ Core Application Files
â”‚   â”œâ”€â”€ main.py                     # FastAPI app with tool integration & all endpoints
â”‚   â”œâ”€â”€ app.py                      # ASGI entrypoint for production deployment
â”‚   â”œâ”€â”€ ai_tools.py                 # 8 production tools (Python, web, weather, etc.)
â”‚   â”œâ”€â”€ database_manager.py         # Centralized database operations (Redis + ChromaDB)
â”‚   â”œâ”€â”€ database.py                 # Database management with connection pooling
â”‚   â”œâ”€â”€ rag.py                      # RAG (Retrieval-Augmented Generation) implementation
â”‚   â””â”€â”€ upload.py                   # File upload and document processing
â”‚
â”œâ”€â”€ ğŸ§  Enhanced Intelligence
â”‚   â”œâ”€â”€ adaptive_learning.py        # Self-learning system with feedback loops
â”‚   â”œâ”€â”€ enhanced_integration.py     # Enhanced endpoints for advanced features
â”‚   â”œâ”€â”€ enhanced_document_processing.py  # Advanced document chunking & analysis
â”‚   â””â”€â”€ model_manager.py            # LLM model management and optimization
â”‚
â”œâ”€â”€ ğŸ›¡ï¸ System Management
â”‚   â”œâ”€â”€ error_handler.py            # Enterprise error handling & recovery
â”‚   â”œâ”€â”€ watchdog.py                 # System health monitoring & alerting
â”‚   â”œâ”€â”€ human_logging.py            # Beautiful console logging with emojis
â”‚   â”œâ”€â”€ feedback_router.py          # User feedback collection & processing
â”‚   â””â”€â”€ storage_manager.py          # File storage and management
â”‚
â”œâ”€â”€ ğŸš€ Deployment & Configuration
â”‚   â”œâ”€â”€ Dockerfile                  # Optimized container build (llama user)
â”‚   â”œâ”€â”€ docker-compose.yml          # Multi-service orchestration
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies with versions
â”‚   â”œâ”€â”€ persona.json               # AI personality configuration
â”‚   â””â”€â”€ refresh-models.py           # Python model refresh utility
â”‚   â””â”€â”€ persona.json               # AI personality configuration
â”‚
â”œâ”€â”€ ï¿½ Shell Scripts & Utilities
â”‚   â”œâ”€â”€ startup.sh                  # Container initialization script
â”‚   â”œâ”€â”€ fix-permissions.sh          # Linux permissions setup script
â”‚   â”œâ”€â”€ manage-models.sh            # Model management utilities
â”‚   â”œâ”€â”€ test-model.sh               # Model testing script
â”‚   â”œâ”€â”€ add-model.sh                # Add new models to Ollama
â”‚   â”œâ”€â”€ enhanced-add-model.sh       # Enhanced model addition script
â”‚   â”œâ”€â”€ debug-openwebui-models.sh   # OpenWebUI model debugging
â”‚   â”œâ”€â”€ setup-github.sh             # GitHub repository setup
â”‚   â””â”€â”€ refresh-models.py           # Python model refresh utility
â”‚
â”œâ”€â”€ ï¿½ğŸ“ Data Storage (Persistent Volumes)
â”‚   â”œâ”€â”€ storage/backend/            # Application data storage
â”‚   â”œâ”€â”€ storage/models/             # Embedding model cache (Qwen3-0.6B)
â”‚   â”œâ”€â”€ storage/chroma/             # Vector database (ChromaDB + ONNX cache)
â”‚   â”œâ”€â”€ storage/redis/              # Redis persistence data
â”‚   â”œâ”€â”€ storage/ollama/             # LLM models (llama3.2:3b + keys)
â”‚   â””â”€â”€ storage/openwebui/          # Web UI data & vector DB
â”‚
â””â”€â”€ ğŸ“š Documentation
    â””â”€â”€ README.md                   # This comprehensive guide
```

### ğŸ”§ Core Components Details

#### **main.py** - FastAPI Application Core (1400+ lines)
- **20+ API Endpoints**: Chat, health, models, feedback, enhanced features
- **Tool Orchestration**: Intelligent tool detection, selection, and execution
- **Streaming Support**: Server-sent events with error recovery
- **Session Management**: Concurrent streaming with automatic cleanup
- **OpenAI Compatibility**: Full `/v1/chat/completions` and `/v1/models` support

#### **ai_tools.py** - Advanced Tool Engine (367 lines)
- **8 Production Tools**: Time, weather, Python execution, web search, Wikipedia, math, text chunking, unit conversion
- **Security**: RestrictedPython sandbox with timeout protection
- **Intelligence**: Automatic knowledge storage and semantic indexing
- **Performance**: Caching and optimized execution

#### **database_manager.py** + **database.py** - Data Management
- **Dual Database**: Redis (cache/sessions) + ChromaDB (vectors/memory)
- **Connection Pooling**: Optimized with automatic retry and recovery
- **Embedding Pipeline**: Qwen3-Embedding-0.6B with fallback support
- **Health Monitoring**: Real-time status and performance metrics

#### **Enhanced Intelligence Modules**
- **adaptive_learning.py**: Self-learning with 5 feedback types and pattern recognition
- **enhanced_document_processing.py**: 5 chunking strategies for 5 document types
- **enhanced_integration.py**: 7 advanced endpoints for learning and documents

#### **System Management**
- **error_handler.py**: 5 specialized error handlers with graceful degradation
- **watchdog.py**: 24/7 monitoring of 3 core services with health history
- **human_logging.py**: Beautiful logs with emojis and color coding

## ğŸ”¬ Complete System Capabilities

### ğŸ¤– LLM & Model Management
- **Default Model**: llama3.2:3b (2GB) with automatic download
- **Model Verification**: Startup checks and manual verification endpoints
- **Embedding System**: Qwen3-Embedding-0.6B (1024-dim vectors) with fallback
- **OpenAI Compatibility**: Full API compatibility with streaming support

### ğŸ› ï¸ Tool Integration (8 Tools)
1. **â° Time & Date**: Current time with timezone support + external API lookup
2. **ğŸŒ¤ï¸ Weather**: Dual-source weather (Open-Meteo + WeatherAPI.com)
3. **ğŸ Python Execution**: Sandboxed code execution with security controls
4. **ğŸŒ Web Search**: DuckDuckGo search with automatic knowledge storage
5. **ğŸ“š Wikipedia**: Article retrieval with configurable summary length
6. **ğŸ§® Mathematics**: Safe expression evaluation and calculations
7. **ğŸ”„ Text Processing**: Advanced chunking with overlap control
8. **ğŸ“ Unit Conversion**: 6 categories, 20+ units (temp, length, weight, etc.)

### ğŸ§  Memory & Storage Systems
- **Short-term Memory**: Redis-based chat history with TTL management
- **Long-term Memory**: ChromaDB vector storage with semantic search
- **Automatic Indexing**: Web search results and interactions stored
- **Context Awareness**: Semantic retrieval across user sessions
- **Persistent Storage**: Docker volumes for data persistence

### ğŸ”’ Security & Performance
- **Sandboxed Execution**: RestrictedPython for code safety
- **Connection Pooling**: Optimized database connections
- **Timeout Protection**: Configurable timeouts for all operations
- **Input Validation**: Comprehensive request validation
- **Error Recovery**: Automatic retry logic for transient failures

### ğŸ“Š Enhanced Intelligence Features
- **Adaptive Learning**: 5 feedback types with pattern recognition
- **Document Processing**: 5 chunking strategies for 5 document types
- **User Insights**: Personalized recommendations and preferences
- **Quality Scoring**: Content quality assessment and optimization
- **Performance Analytics**: Response time and engagement tracking

### ğŸ¥ Monitoring & Health
- **System Watchdog**: 24/7 monitoring of 3 core services
- **Health Endpoints**: 7 health check endpoints with detailed status
- **Performance Metrics**: Response time, error rates, resource usage
- **Health History**: 24-hour rolling history with trend analysis
- **Graceful Degradation**: Continues operation when subsystems fail

### ğŸ”Œ API Architecture (20+ Endpoints)
- **Chat Endpoints**: Main chat, OpenAI-compatible, enhanced chat
- **Model Management**: List, verify, download models
- **Health Monitoring**: Basic, detailed, service-specific health
- **Document Processing**: Upload, advanced processing, RAG
- **Enhanced Features**: Learning feedback, insights, strategies
- **Streaming Support**: Real-time responses with session management

### ğŸ› ï¸ Advanced Tool Suite

#### ğŸ”§ Available Tools (ai_tools.py)
1. **â° Time & Date Services**
   - `get_current_time(timezone)` - Current time with timezone support
   - `get_time_from_timeanddate(location)` - Time lookup from external API

2. **ğŸŒ¤ï¸ Weather Services**
   - `get_weather(city)` - Open-Meteo weather with WeatherAPI.com fallback
   - `get_weather_weatherapi(city)` - Direct WeatherAPI.com integration

3. **ğŸ Secure Python Code Execution**
   - `run_python_code(code)` - Sandboxed Python execution with timeout protection
   - RestrictedPython environment with security controls
   - Result capturing and error handling

4. **ğŸŒ Intelligent Web Search**
   - DuckDuckGo search with automatic knowledge storage
   - Real-time web content retrieval and indexing
   - Semantic storage for future reference

5. **ğŸ“š Wikipedia Integration**
   - `wikipedia_search(query, sentences)` - Smart article retrieval with summary extraction
   - Configurable summary length (1-10 sentences)
   - Automatic caching and error handling

6. **ğŸ§® Mathematical Computing**
   - Safe expression evaluation with comprehensive operator support
   - Mathematical functions and calculations
   - Error handling for invalid expressions

7. **ğŸ”„ Text Processing**
   - `chunk_text(text, chunk_size, chunk_overlap)` - Advanced text chunking with overlap
   - Recursive character splitting for optimal content organization
   - Configurable chunk sizes and overlap parameters

8. **ğŸ“ Unit Conversion**
   - `convert_units(value, from_unit, to_unit)` - Comprehensive unit conversion
   - Temperature: Celsius â†” Fahrenheit â†” Kelvin
   - Length: meters â†” feet â†” inches â†” yards â†” kilometers â†” miles
   - Weight: kilograms â†” pounds â†” ounces â†” grams
   - Volume: liters â†” gallons â†” milliliters â†” fluid ounces
   - Speed: m/s â†” km/h â†” mph â†” knots
   - Energy: joules â†” calories â†” BTU â†” kWh

### ğŸ§  Intelligent Memory System
- **Short-term Memory**: Redis-based chat history with automatic expiration
- **Long-term Memory**: ChromaDB semantic memory with vector embeddings
- **Automatic Knowledge Storage**: Web search results automatically indexed for future retrieval
- **Context-Aware Retrieval**: Semantic search across user's historical interactions
- **Context-Aware Caching**: Smart cache keys based on user intent

### ğŸ”„ Streaming & API Compatibility
- **Real-time Streaming**: Server-sent events (SSE) for live responses with error recovery
- **OpenAI Compatible**: `/v1/chat/completions` and `/v1/models` endpoints with full feature parity
- **Multiple API Formats**: Support for various client integrations and frameworks
- **Session Management**: Handle concurrent streaming sessions with automatic cleanup
- **Request Tracking**: Unique request IDs for debugging and performance analysis

### ğŸ”’ Security & Performance
- **Sandboxed Code Execution**: Restricted Python environment with security controls
- **Intelligent Caching**: Redis-based response caching with TTL management
- **Timeout Protection**: Configurable timeouts prevent long-running operations
- **Connection Pooling**: Optimized database connections with automatic recovery
- **Resource Monitoring**: Memory and CPU usage tracking with alerts

### ğŸ›¡ï¸ Enterprise-Grade Error Handling
- **Centralized Error Management**: Dedicated error handling module (`error_handler.py`) with specialized handlers
- **Graceful Degradation**: System continues operating when subsystems fail (Redis offline, ChromaDB unavailable)
- **User-Friendly Messages**: Technical errors converted to helpful user messages with context
- **Specialized Handlers**: Different error handling strategies for chat, tools, cache, memory, and Redis operations
- **Request Tracking**: Unique request IDs for error correlation, debugging, and audit trails
- **Safe Execution**: Wrapper functions for critical operations with configurable fallback values
- **Context-Aware Logging**: Detailed error context including user ID, operation type, input data, and system state
- **Automatic Recovery**: Built-in retry logic for transient network errors and connection issues

## ğŸ§  Enhanced Learning & Document Processing

### ğŸ¯ Adaptive Learning System (adaptive_learning.py)

#### Core Components
1. **ConversationAnalyzer**
   - Analyzes user interactions for learning patterns
   - Extracts topics, sentiment, and feedback classification
   - Calculates context relevance and engagement metrics

2. **AdaptiveLearningSystem**
   - Processes feedback loops for continuous improvement
   - Learns user preferences and interaction patterns
   - Automatically expands knowledge base from interactions
   - Provides personalized recommendations

#### Feedback Types
- **POSITIVE**: Good, helpful responses
- **NEGATIVE**: Incorrect or unhelpful responses  
- **NEUTRAL**: Standard interactions
- **CORRECTION**: User corrections to AI responses
- **CLARIFICATION**: Follow-up questions for better understanding

#### Learning Patterns
- **Query Patterns**: Common question types and preferences
- **Context Preferences**: User's preferred information depth and style
- **Tool Preferences**: Most effective tools for specific user needs

### ğŸ“„ Enhanced Document Processing (enhanced_document_processing.py)

#### Document Types
- **TEXT**: Plain text documents
- **CODE**: Source code with syntax awareness
- **ACADEMIC**: Research papers and academic content
- **TECHNICAL**: Technical documentation and manuals
- **MIXED**: General documents with varied content

#### Chunking Strategies
- **SEMANTIC**: Content-aware chunking based on meaning
- **FIXED_SIZE**: Traditional fixed-size chunks with overlap
- **PARAGRAPH**: Paragraph-boundary-aware chunking
- **SENTENCE**: Sentence-level chunking for precision
- **ADAPTIVE**: Dynamic chunking based on content analysis

#### Document Analysis Features
- **Language Detection**: Automatic language identification
- **Content Complexity**: Readability and technical complexity scoring
- **Topic Extraction**: Key theme and subject identification
- **Structure Analysis**: Document organization and hierarchy detection

#### Processing Pipeline
1. **Document Upload** â†’ **Content Analysis** â†’ **Strategy Selection**
2. **Intelligent Chunking** â†’ **Quality Scoring** â†’ **Vector Storage**
3. **Metadata Extraction** â†’ **Index Creation** â†’ **Semantic Search Ready**

## ğŸ”Œ API Endpoints

### ğŸ“‹ Core Chat & Streaming Endpoints
- **`POST /chat`** - Main chat endpoint with tool integration and memory
- **`POST /v1/chat/completions`** - OpenAI-compatible chat completions with streaming
- **`POST /api/chat/completions`** - Alternative chat completions endpoint
- **`POST /v1/stop_stream`** - Stop active streaming sessions
- **`POST /api/stop_stream`** - Alternative stream stopping endpoint

### ğŸ¤– Model Management
- **`GET /v1/models`** - List available models (OpenAI-compatible)
- **`GET /v1/models/verify/{model_name}`** - Verify and download specific models
- **`GET /capabilities`** - System capabilities and feature overview

### ğŸ¥ Health & Monitoring
- **`GET /health`** - Basic system health check
- **`GET /health/simple`** - Simplified health status
- **`GET /health/detailed`** - Comprehensive health with all subsystems
- **`GET /health/redis`** - Redis-specific health status
- **`GET /health/chromadb`** - ChromaDB-specific health status
- **`GET /health/history/{service_name}`** - Service health history (24h)
- **`GET /health/storage`** - Storage system health and usage

### ğŸ“ Document & RAG
- **File upload endpoints** (integrated from upload.py)
- **Document processing** with vector storage
- **Semantic search** across uploaded documents

## ï¿½ System Monitoring & Health Management

### Comprehensive Watchdog System (watchdog.py)
The backend includes an enterprise-grade monitoring system that continuously tracks the health of all critical subsystems:

**Monitored Services:**
- **Redis**: Connection health, response time, memory usage, client connections, operational status
- **ChromaDB**: Collection access, document operations, query performance, storage health
- **Ollama**: API connectivity, model availability, response times, service status

**Watchdog Features:**
- **Delayed Startup**: Configurable startup delay (default: 10 seconds) to ensure all services are ready
- **Continuous Monitoring**: Configurable check intervals (default: 30 seconds) with async execution  
- **Health History**: 24-hour rolling history with timestamps and performance metrics
- **Intelligent Alerting**: Configurable alert thresholds with automatic escalation
- **Graceful Degradation**: System continues operating even when monitoring services fail
- **Performance Metrics**: Response time tracking, error rate analysis, and trend detection
- **Automatic Recovery**: Built-in reconnection logic for transient failures (broken pipe errors, network timeouts)
- **Real-time Status**: Live health dashboard with service-specific details
- **Smart Initialization**: Starts after FastAPI app initialization to prevent startup conflicts

### Health Check Endpoints

```bash
# Basic health check
GET /health

# Detailed health with all subsystems
GET /health/detailed

# Individual service health
GET /health/redis
GET /health/chromadb  

# Service health history
GET /health/history/{service_name}?hours=24

# Storage system health
GET /health/storage
```

### Watchdog Configuration

Environment variables for watchdog configuration:
```bash
WATCHDOG_CHECK_INTERVAL=30    # Seconds between checks
WATCHDOG_TIMEOUT=5            # Timeout for health checks
WATCHDOG_MAX_RETRIES=3        # Retry attempts before marking unhealthy
WATCHDOG_ALERT_THRESHOLD=3    # Consecutive failures before alert
```

### Testing the Watchdog

```bash
# Monitor the system logs
docker logs -f backend-llm-backend

# Check individual service health
curl http://localhost:8001/health/redis
curl http://localhost:8001/health/chromadb

# Test system health monitoring
curl http://localhost:8001/health/detailed
```

### Health Status Values

- **healthy**: Service is fully operational
- **degraded**: Service has issues but is partially functional
- **unhealthy**: Service is not responding or has critical errors
- **unknown**: Unable to determine service status

## ğŸ“‚ Project Organization

This project follows a clean, organized structure that separates concerns and makes development efficient:

```
ğŸ“ Root Directory - Core Application
â”œâ”€â”€ main.py                 # FastAPI backend entry point  
â”œâ”€â”€ ai_tools.py            # AI tool implementations
â”œâ”€â”€ database_manager.py    # Database operations
â”œâ”€â”€ cache_manager.py       # Redis cache operations  
â”œâ”€â”€ human_logging.py       # Enhanced logging system
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ requirements.txt       # Dependencies

ğŸ“ demo-tests/ - Development & Testing
â”œâ”€â”€ cache-tests/           # Cache system tests
â”œâ”€â”€ debug-tools/          # Debugging utilities
â”œâ”€â”€ integration-tests/    # Full system tests
â”œâ”€â”€ model-tests/         # AI model tests
â”œâ”€â”€ results/             # Test result files
â””â”€â”€ *.py                 # Test and demo scripts

ğŸ“ readme/ - Documentation
â”œâ”€â”€ ORGANIZATION_SUMMARY.md    # This organization guide
â”œâ”€â”€ ai_tools_test_report.md   # AI tools test results
â”œâ”€â”€ CURRENT_STATUS.md         # Project status
â””â”€â”€ *.md                      # Technical reports & guides

ğŸ“ utils/ - Shared Utilities
â””â”€â”€ Shared utility functions

ğŸ“ storage/ - Data Storage  
â””â”€â”€ Runtime data storage (created automatically)
```

**Benefits:**
- ğŸ¯ **Clear Separation**: Production code, tests, and docs are separated
- ğŸ” **Easy Navigation**: Developers know exactly where to find files
- ğŸš€ **Clean Deployment**: Root contains only production-ready code
- ğŸ“š **Centralized Docs**: All documentation in one organized location

## ğŸ“¡ API Endpoints

## ğŸ“¡ API Endpoints

### Chat Endpoints
- `POST /chat` - Main chat interface with tool support
- `POST /v1/chat/completions` - OpenAI-compatible chat completions
- `POST /api/chat/completions` - Alternative OpenWebUI endpoint

### Model Management
- `GET /v1/models` - List available models
- `GET /v1/models/verify/{model_name}` - Verify and download models
- `GET /test` - Backend status and default model info
- `POST /v1/stop_stream` - Stop streaming sessions
- `POST /api/stop_stream` - Alternative stop endpoint

### File Upload & RAG
- `POST /upload` - Upload documents for RAG processing
- `POST /search` - Search uploaded documents
- `GET /documents` - List uploaded documents
- `DELETE /documents/{doc_id}` - Delete documents

### Health & Monitoring
- `GET /health` - System health check
- `GET /health/detailed` - Detailed system monitoring
- Service-specific health monitoring

## ğŸ“š Documentation

For comprehensive project documentation, visit the [readme/](readme/) directory which contains:

- **Project Status Reports** - Final achievements and completion summaries
- **Code Review Reports** - Detailed code analysis and quality metrics
- **Testing Documentation** - Comprehensive test reports and results
- **System Health Reports** - Service monitoring and health verification
- **Cleanup & Maintenance** - Code cleanup and optimization reports
- **Technical Analysis** - Duplicate code analysis and refactoring plans

See [readme/README.md](readme/README.md) for a complete documentation index.

---

*Project Status: **COMPLETED** âœ… - All tests passing, services healthy, code quality optimized*
