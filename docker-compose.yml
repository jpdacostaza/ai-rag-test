services:
  # Redis - Memory cache and short-term storage
  redis:
    image: redis:7-alpine
    container_name: backend-redis
    ports:
      - "6379:6379"
    restart: always
    volumes:
      - ./storage/redis:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - backend-net

  # ChromaDB - Vector database for embeddings
  chroma:
    image: chromadb/chroma:latest
    container_name: backend-chroma
    ports:
      - "8000:8000"
    restart: always
    volumes:
      - ./storage/chroma:/chroma/chroma
    networks:
      - backend-net

  # Ollama - Language model service
  ollama:
    image: ollama/ollama:latest
    container_name: backend-ollama
    ports:
      - "11434:11434"
    restart: always
    volumes:
      - ./storage/ollama:/root/.ollama
    environment:
      - OLLAMA_ORIGINS="*"
      - OLLAMA_HOST=0.0.0.0:11434
    healthcheck:
      test: ["CMD-SHELL", "pgrep ollama || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - backend-net

  # Main Backend API - Primary FastAPI application
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: backend-main
    ports:
      - "3000:3000"
    restart: always
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CHROMA_HOST=chroma
      - CHROMA_PORT=8000
      - OLLAMA_BASE_URL=http://ollama:11434
      - DEFAULT_MODEL=llama3.2:3b
      - EMBEDDING_MODEL=intfloat/e5-small-v2
      - EMBEDDING_PROVIDER=huggingface
      - USE_HTTP_CHROMA=true
      - SENTENCE_TRANSFORMERS_HOME=./storage/models
    volumes:
      - ./storage/backend:/app/data
      - ./storage/models:/app/models
      - ./storage/.cache:/root/.cache
    depends_on:
      redis:
        condition: service_healthy
      chroma:
        condition: service_started
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health", "||", "exit", "1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - backend-net

  # Integrated Memory API - Enhanced memory system with built-in auto-setup
  memory_api:
    build:
      context: .
      dockerfile: Dockerfile.memory
    container_name: backend-memory-api
    ports:
      - "8001:8080"  # Use different internal port to avoid conflict with ChromaDB
    restart: always
    environment:
      - REDIS_URL=redis://redis:6379
      - CHROMA_URL=http://chroma:8000
      - OLLAMA_API=http://ollama:11434
      - OPENWEBUI_API=http://openwebui:8080
    volumes:
      - ./storage/memory:/app/data
      - ./storage/openwebui:/tmp/openwebui:rw  # Shared database access
    depends_on:
      redis:
        condition: service_healthy
      chroma:
        condition: service_started
      # Remove ollama dependency for initial startup - memory_api will wait for it internally
    networks:
      - backend-net

  # OpenWebUI - Main web interface  
  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: backend-openwebui
    ports:
      - "8080:8080"
    restart: always
    environment:
      # Route through our main backend API
      - OLLAMA_BASE_URL=http://backend:3000
      - OPENAI_API_BASE_URLS=http://backend:3000
      - OPENAI_API_KEYS=backend-api-key
      - ENABLE_FUNCTIONS=true
      - ENABLE_COMMUNITY_SHARING=false
      - WEBUI_AUTH=true
      - ENABLE_SIGNUP=true
      - DEFAULT_USER_ROLE=user
      - DEFAULT_MODELS=llama3.2:3b
      # Disable direct Ollama access to force routing through backend
      - ENABLE_OLLAMA_API=false
    volumes:
      - ./storage/openwebui:/app/backend/data
      - ./memory/functions:/app/backend/data/functions:rw
    depends_on:
      - backend
      - memory_api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health", "||", "exit", "1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - backend-net

  # Function Installer - One-time installer for memory functions
  function_installer:
    build:
      context: .
      dockerfile: Dockerfile.function-installer
    container_name: backend-function-installer
    restart: "no"  # One-time container
    environment:
      - OPENWEBUI_URL=http://openwebui:8080
    depends_on:
      - openwebui
    networks:
      - backend-net
    profiles:
      - installer  # Optional profile

  # Watchtower - Automatic container updates (optional)
  watchtower:
    image: containrrr/watchtower:latest
    container_name: backend-watchtower
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_POLL_INTERVAL=3600  # Check every hour
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_INCLUDE_RESTARTING=true
    networks:
      - backend-net
    profiles:
      - optional  # Disabled by default

networks:
  backend-net:
    driver: bridge
