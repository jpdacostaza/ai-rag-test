#!/usr/bin/env python3
"""
Test script to verify the embedding model download logic.
"""
import os
import sys
import asyncio
import logging

# Add the current directory to Python path
sys.path.insert(0, os.path.dirname(__file__))

# Set up basic logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


async def test_embedding_download():
    """Test the embedding model download and initialization."""
    try:
        print("ğŸ”§ Testing embedding model download logic...")

        # Import configuration
        from config import EMBEDDING_MODEL, EMBEDDING_PROVIDER, SENTENCE_TRANSFORMERS_HOME, AUTO_PULL_MODELS

        print(f"ğŸ“‹ Configuration:")
        print(f"   EMBEDDING_MODEL: {EMBEDDING_MODEL}")
        print(f"   EMBEDDING_PROVIDER: {EMBEDDING_PROVIDER}")
        print(f"   SENTENCE_TRANSFORMERS_HOME: {SENTENCE_TRANSFORMERS_HOME}")
        print(f"   AUTO_PULL_MODELS: {AUTO_PULL_MODELS}")

        # Create models directory if it doesn't exist
        os.makedirs(SENTENCE_TRANSFORMERS_HOME, exist_ok=True)
        print(f"ğŸ“ Models directory: {os.path.abspath(SENTENCE_TRANSFORMERS_HOME)}")

        # Check if model exists locally
        model_dir = os.path.join(SENTENCE_TRANSFORMERS_HOME, EMBEDDING_MODEL.replace("/", "_"))
        model_exists = os.path.exists(model_dir) and os.listdir(model_dir)
        print(f"ğŸ” Model directory exists: {model_exists}")
        print(f"   Model path: {model_dir}")

        if model_exists:
            print(f"ğŸ“¦ Model files found:")
            for file in os.listdir(model_dir):
                print(f"   - {file}")

        if EMBEDDING_PROVIDER.lower() == "huggingface":
            print("ğŸ¤— Testing HuggingFace model download...")

            # Set environment variable for cache
            os.environ["SENTENCE_TRANSFORMERS_HOME"] = SENTENCE_TRANSFORMERS_HOME

            if not model_exists and AUTO_PULL_MODELS:
                print(f"ğŸ“¥ Model '{EMBEDDING_MODEL}' not found locally. Downloading...")

                def download_model():
                    """TODO: Add proper docstring for download_model."""
                    try:
                        from sentence_transformers import SentenceTransformer

                        print(f"ğŸ”„ Starting download of {EMBEDDING_MODEL}...")
                        model = SentenceTransformer(EMBEDDING_MODEL, cache_folder=SENTENCE_TRANSFORMERS_HOME)
                        print(f"âœ… Model downloaded successfully!")
                        print(f"ğŸ“Š Model dimensions: {model.get_sentence_embedding_dimension()}")
                        return model
                    except Exception as e:
                        print(f"âŒ Failed to download model: {e}")
                        return None

                # Download the model
                model = await asyncio.to_thread(download_model)

                if model is not None:
                    print("ğŸ§ª Testing embedding generation...")

                    # Test embedding generation
                    test_text = "This is a test sentence for embedding generation."
                    if "e5-" in EMBEDDING_MODEL.lower():
                        prefixed_text = f"query: {test_text}"
                    else:
                        prefixed_text = test_text

                    def generate_embedding():
                        """TODO: Add proper docstring for generate_embedding."""
                        try:
                            embedding = model.encode([prefixed_text], normalize_embeddings=True)
                            return embedding[0].tolist() if len(embedding) > 0 else None
                        except Exception as e:
                            print(f"âŒ Failed to generate embedding: {e}")
                            return None

                    embedding = await asyncio.to_thread(generate_embedding)

                    if embedding:
                        print(f"âœ… Successfully generated embedding!")
                        print(f"ğŸ“ Embedding length: {len(embedding)}")
                        print(f"ğŸ”¢ First 5 values: {embedding[:5]}")
                    else:
                        print("âŒ Failed to generate embedding")

            elif model_exists:
                print(f"ğŸ“ Loading existing model from cache...")

                def load_existing_model():
                    """TODO: Add proper docstring for load_existing_model."""
                    try:
                        from sentence_transformers import SentenceTransformer

                        model = SentenceTransformer(EMBEDDING_MODEL, cache_folder=SENTENCE_TRANSFORMERS_HOME)
                        print(f"âœ… Model loaded successfully!")
                        print(f"ğŸ“Š Model dimensions: {model.get_sentence_embedding_dimension()}")
                        return model
                    except Exception as e:
                        print(f"âŒ Failed to load cached model: {e}")
                        return None

                model = await asyncio.to_thread(load_existing_model)

                if model is not None:
                    print("ğŸ§ª Testing embedding generation with cached model...")

                    # Test embedding generation
                    test_text = "This is a test sentence for embedding generation."
                    if "e5-" in EMBEDDING_MODEL.lower():
                        prefixed_text = f"query: {test_text}"
                    else:
                        prefixed_text = test_text

                    def generate_embedding():
                        """TODO: Add proper docstring for generate_embedding."""
                        try:
                            embedding = model.encode([prefixed_text], normalize_embeddings=True)
                            return embedding[0].tolist() if len(embedding) > 0 else None
                        except Exception as e:
                            print(f"âŒ Failed to generate embedding: {e}")
                            return None

                    embedding = await asyncio.to_thread(generate_embedding)

                    if embedding:
                        print(f"âœ… Successfully generated embedding!")
                        print(f"ğŸ“ Embedding length: {len(embedding)}")
                        print(f"ğŸ”¢ First 5 values: {embedding[:5]}")
                    else:
                        print("âŒ Failed to generate embedding")

            else:
                print("âš ï¸  Model not found and AUTO_PULL_MODELS is disabled")
                print("ğŸ’¡ Enable AUTO_PULL_MODELS=true to download automatically")

        else:
            print(f"ğŸš« Provider '{EMBEDDING_PROVIDER}' not supported in this test")
            print("ğŸ’¡ This test only supports HuggingFace provider")

    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("ğŸ’¡ Make sure sentence-transformers is installed: pip install sentence-transformers")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    print("ğŸ§ª Embedding Model Download Test")
    print("=" * 50)
    asyncio.run(test_embedding_download())
    print("=" * 50)
    print("ğŸ Test completed!")
